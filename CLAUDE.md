# "지원사업 공고 수집" Project Guidelines

## 목표
주어진 URL의 사이트에 접속하여 사이트에 공지된 지원사업 공고문을 수집하고 첨부파일을 다운로드 하여 로컬디렉토리에 저장한다.
사이트의 공고는 대부분 pagination 기반의 BBS 형태로 되어 있다.
주어진 URL은 1 페이지의  목록 페이지 이다. 목록들은 대부분 10개에서 30개 내외이다.
수집을 위해 목록 상의 첫번째 공고의 링크를 타고 상세 페이지로 이동하여, 상세페이지에서 공고 내용을 markdown 방식으로 저장한다.
공고 본문이 있는 상세페이지에는 공고본문과 첨부파일 링크가 있다. 첨부파일 링크가 있는 경우 첨부파일들을 다운로드 하여 로컬에 저장한다.
각 공고 별로 본문 파일과 첨부파일은 분리되어 저장되어야 한다.

## 세부 단계
- 주어진 URL을 접속하여 html을 다운로드 받는다.
- html의 태그와 엘레멘트를 분석하여 DOM 구조를 파악한다.
- 공고 목록을 파악하여 각 공고의 세부페이지로 이동할 수 있는 링크나 javacript 방법을 찾아낸다.
- 첫번째 공고 상세 페이지로 이동한다.
- 상세페이지의 html를 분석하여 헤더 제목 등은 제외하고 공고 본문만 추려 낼수 있는 태그, 엘레멘트를 찾아내서 해당 부분만을 markdown으로 변환하여 파일로 저장한다.
- 상세패이지의 html을 분석하여 첨부파일이 있으면 첨부파일을 다운로드 받는다.
- 다시 목록 페이지로 되돌아 가서 다음 공고를 위와 같은 방식으로 처리하고 목록의 전체 공고가 처리될때까지 반복한다.
- 주어진 URL의 공고들을 전부 처리했으면 하단의 pagination bar를 분석하여 다음 페이지로 이동한다.
- 다음 페이지도 공고들이 있으므로 이것들으 처리하고 전부 처리되고 나면 다시 다음 페이지로 이동한다.
- 4페이지까지만 반복하고 4페이지가 끝나면 프로그램을 중단한다.

## 새로운 메모리
- 스크래퍼 개발 시 robots.txt는 무시하고 진행한다.
- 각 웹사이트마다 스크래핑 구조가 다르므로 유연한 접근 방식 필요
- to memorize