# KEPCO(한국전력공사) 스크래퍼 개발 인사이트

## 프로젝트 개요
- **사이트**: 한국전력공사 공지사항 (https://home.kepco.co.kr/kepco/CY/K/ntcob/list.do)
- **개발일**: 2025-07-18
- **수집 범위**: 3페이지 (총 30개 공고)
- **성공 여부**: ✅ 완료 (30개 공고 수집, 47개 첨부파일 다운로드)

## 사이트 특성 분석

### 1. URL 구조
- **복잡한 파라미터**: 매우 복잡한 GET 파라미터 구조
- **페이지네이션**: `pageIndex` 파라미터로 페이지 이동
- **고정 파라미터**: boardSeq, parnScrpSeq, boardCd, menuCd 등 다수의 고정값 필요

### 2. 네비게이션 방식
- **JavaScript 기반**: `fncGoView('boardSeq')` 함수로 상세 페이지 이동
- **복잡한 URL 구성**: 상세 페이지 URL은 목록 페이지 파라미터 + 특정 boardSeq 조합
- **세션 관리**: 정부 사이트 특성상 세션 유지 필요

### 3. HTML 구조
- **목록 페이지**: `<table class="list">` 구조
- **상세 페이지**: `<dt><dd>` 정의 리스트 구조
- **첨부파일**: `FileDownSecure.do` 엔드포인트 사용

## 주요 기술적 도전과제

### 1. JavaScript URL 파싱
```python
# fncGoView('21069731') 패턴에서 boardSeq 추출
onclick = title_link.get('onclick', '')
match = re.search(r"fncGoView\('(\d+)'\)", onclick)
board_seq = match.group(1)
```

### 2. 복잡한 URL 파라미터 관리
```python
# 고정 파라미터 관리
self.base_params = {
    'boardSeq': '21069447',
    'parnScrpSeq': '21069447',
    'depth': '0',
    'boardNo': '0',
    'boardCd': 'BRD_000039',
    'replyRole': '',
    'searchKeyword': '',
    'searchCondition': 'total',
    'menuCd': 'FN02070501'
}
```

### 3. 첨부파일 다운로드 특성
- **암호화된 URL**: `FileDownSecure.do?atchFileId=...&fileSn=...`
- **Referer 헤더 필수**: 상세 페이지 URL을 Referer로 설정
- **한글 파일명**: UTF-8 인코딩으로 완전 지원

## 성공 요인

### 1. 베이스 스크래퍼 활용
- **상속 구조**: `EnhancedBaseScraper` 클래스 완전 활용
- **메서드 시그니처**: 기본 `download_file` 메서드 사용으로 호환성 확보

### 2. 다층 파싱 전략
```python
# 여러 방법으로 본문 추출 시도
# 1. dt 태그에서 제목 추출
# 2. 메타데이터 테이블 추출
# 3. dd.view_cont div.cont에서 본문 추출
# 4. 전체 dd.view_cont에서 추출
# 5. 단락별 추출 (마지막 수단)
```

### 3. 첨부파일 추출 전략
```python
# 3단계 첨부파일 추출
# 1. dd.file 섹션에서 추출
# 2. 전체 페이지 FileDownSecure.do 링크 찾기
# 3. JavaScript onclick 패턴 찾기
```

## 발견된 이슈와 해결방법

### 1. 메서드 시그니처 호환성
**문제**: 커스텀 `download_file` 메서드가 베이스 스크래퍼와 시그니처 불일치
**해결**: 베이스 스크래퍼의 `download_file` 메서드 사용으로 변경

### 2. 파일 다운로드 검증
**문제**: HTML 페이지가 파일로 다운로드되는 경우 발생
**해결**: 베이스 스크래퍼의 Content-Type 검증 및 파일 크기 검증 활용

### 3. 한글 파일명 처리
**문제**: 한글 파일명의 URL 인코딩 및 파일 시스템 호환성
**해결**: 베이스 스크래퍼의 `_make_safe_filename` 메서드 활용

## 성능 통계
- **총 수집 공고**: 30개
- **총 첨부파일**: 47개
- **수집 시간**: 약 4분 (평균 8초/공고)
- **성공률**: 100% (모든 공고 및 첨부파일 성공적 수집)

## 파일 구조
```
output/kepco/
├── 001_2025년_축냉설비_보급_지원사업_종료_알림/
├── 002_2025년_최대전력관리장치_보급사업_시행_공고/
│   ├── content.md
│   └── attachments/
│       ├── 붙임서식_1._최대전력관리장치_지원금_신청서.hwp
│       ├── 붙임서식_2._최대전력관리장치_개인정보수집,_이용동의서.hwp
│       └── 붙임서식_3._최대전력관리장치_준공확인서.hwp
├── ... (30개 공고 폴더)
└── processed_titles_enhancedkepco.json
```

## 다음 개발자를 위한 권장사항

### 1. 개발 전 준비
- **베이스 스크래퍼 숙지**: `EnhancedBaseScraper` 클래스 완전 이해 필수
- **정부 사이트 특성**: 세션 관리 및 복잡한 파라미터 구조 이해
- **브라우저 분석**: 개발자 도구로 JavaScript 네비게이션 분석

### 2. 코드 작성 시 주의사항
- **메서드 오버라이드 최소화**: 베이스 스크래퍼 메서드 최대한 활용
- **다층 파싱 전략**: 한 가지 방법이 실패해도 대안 방법 준비
- **로깅 강화**: 각 단계별 상세 로그로 디버깅 용이성 확보

### 3. 테스트 전략
- **단계별 테스트**: 1페이지 → 3페이지 → 전체 순서로 테스트
- **한글 파일명 확인**: UTF-8 인코딩 및 파일 시스템 호환성 검증
- **파일 크기 검증**: 다운로드된 파일의 크기 및 내용 확인

## 핵심 교훈
1. **베이스 스크래퍼 활용이 핵심**: 커스텀 구현보다는 기존 메서드 활용이 안정적
2. **정부 사이트의 복잡성**: 단순한 접근보다는 다층 전략 필요
3. **한글 지원 완성도**: 베이스 스크래퍼의 한글 파일명 처리 능력 우수
4. **점진적 접근**: 1페이지 테스트 → 전체 테스트 순서 중요

이 인사이트를 바탕으로 다른 정부 사이트 스크래퍼 개발 시 유사한 접근 방식을 적용할 수 있을 것입니다.