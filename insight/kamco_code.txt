# 한국자산관리공사(KAMCO) Enhanced 스크래퍼 개발 인사이트

## 사이트 특성 분석
- **URL**: https://www.kamco.or.kr/portal/bbs/list.do?ptIdx=380&mId=0701010000
- **사이트 유형**: 표준 HTML 테이블 기반 게시판
- **페이지네이션**: GET 파라미터 `page=N` 방식
- **인코딩**: UTF-8
- **SSL**: 정상 작동 (verify=True)

## 기술적 구현 특징

### 1. JavaScript 기반 네비게이션 처리
KAMCO 사이트는 일반적인 href 링크 대신 JavaScript 함수를 사용합니다:

```javascript
// 상세 페이지 이동
onclick="goTo.view('list','18905','380','0701010000')"

// 파일 다운로드
onclick="fn_egov_downFile('FILE_000000000009941','0')"
```

**해결 방법**:
```python
# goTo.view 패턴 파싱
onclick_match = re.search(r"goTo\.view\(['\"]([^'\"]+)['\"],\s*['\"](\d+)['\"],\s*['\"](\d+)['\"],\s*['\"]([^'\"]+)['\"]", onclick)
if onclick_match:
    list_type, bidx, ptidx, mid = onclick_match.groups()
    detail_url = f"{self.base_url}/portal/bbs/view.do?mId={mid}&bIdx={bidx}&ptIdx={ptidx}"

# fn_egov_downFile 패턴 파싱  
onclick_match = re.search(r"fn_egov_downFile\(['\"]([^'\"]+)['\"],\s*['\"]([^'\"]*)['\"]", onclick)
if onclick_match:
    file_id, param = onclick_match.groups()
    download_url = f"{self.base_url}/common/fms/FileDown.do?atchFileId={file_id}&fileSn={param}"
```

### 2. 공지 공고 처리
상단에 고정된 "공지" 공고들과 일반 번호 공고들을 모두 수집:

```python
def _process_notice_detection(self, cell, row_index=0):
    number = cell.get_text(strip=True)
    is_notice = False
    
    # 이미지에서 공지 감지
    notice_imgs = cell.find_all('img')
    for img in notice_imgs:
        src = img.get('src', '')
        alt = img.get('alt', '')
        if '공지' in src or '공지' in alt or 'notice' in src.lower():
            is_notice = True
            break
    
    # 텍스트에서 공지 감지
    if '공지' in number:
        is_notice = True
    
    return "공지" if is_notice else (number or f"row_{row_index + 1}")
```

### 3. 첨부파일 다운로드 제한 및 해결책
KAMCO 사이트의 파일 다운로드는 **세션 기반 인증이 필요**합니다:
- 단순 GET 요청으로는 에러 페이지(1,838 bytes HTML) 반환
- 브라우저 자동화(Playwright)로도 다운로드 타임아웃 발생
- 실제 파일 다운로드를 위해서는 브라우저 세션이나 특별한 인증 필요

**현실적인 해결 방안**:
```python
# 파일 메타데이터를 JSON과 마크다운으로 저장
attachments_info = []
for attachment in announcement['attachments']:
    attachments_info.append({
        'filename': attachment.get('filename', 'unknown'),
        'size': attachment.get('size', ''),
        'url': attachment.get('url', ''),
        'note': 'KAMCO 사이트는 세션 인증이 필요하여 직접 다운로드 불가'
    })

# JSON 파일로 저장
with open('attachments_info.json', 'w', encoding='utf-8') as f:
    json.dump(attachments_info, f, ensure_ascii=False, indent=2)

# 마크다운 형태로도 저장하여 가독성 향상
```

### 4. 본문 내용 파싱
다양한 본문 구조에 대응하는 파싱 로직:

```python
def parse_detail_page(self, html_content: str) -> dict:
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # 방법 1: 본문이 포함된 큰 셀 찾기
    content_cells = soup.find_all('td', class_=lambda x: x is None)
    for cell in content_cells:
        cell_text = cell.get_text(strip=True)
        if len(cell_text) > 100 and ('공고' in cell_text or '신청' in cell_text or '모집' in cell_text):
            content = self.h.handle(str(cell)).strip()
            break
    
    # 방법 2: 긴 텍스트가 포함된 td 찾기
    if not content:
        for td in soup.find_all('td'):
            td_text = td.get_text(strip=True)
            if len(td_text) > 50:
                content = self.h.handle(str(td)).strip()
                break
```

## 테스트 결과 및 성능

### 수집 성공률 (2025-06-29 업데이트)
- **3페이지 테스트**: 45개 공고 수집 (15개/페이지 × 3페이지)
- **본문 수집**: 100% 성공 (45/45)
- **첨부파일 메타데이터 수집**: 100% 성공 (36개 공고에서 첨부파일 정보 완벽 추출)
- **실제 파일 다운로드**: 0% (세션 인증 필요, 브라우저 자동화로도 타임아웃)

### 수집된 데이터 품질
```
총 공고 수: 45개
본문 파일: 45개 (.md)
첨부파일 메타데이터: 36개 (JSON + 마크다운 형태)
한글 파일명: 정상 처리 (예: "기업구조혁신펀드_4호_프로젝트펀드_수시모집_공고.hwp")
파일 크기 정보: 정확 (예: "32.5 KByte", "2.3 MByte")
다운로드 URL: 완전한 형태로 보존
```

### 메타데이터 기반 접근법의 장점
1. **완전한 정보 보존**: 파일명, 크기, URL 모두 정확히 추출
2. **가독성**: 마크다운 형태로 사람이 읽기 쉬운 형태 제공
3. **구조화**: JSON 형태로 프로그래밍 방식 접근 가능
4. **추적 가능성**: 실제 다운로드 제약 사항을 명확히 문서화

### 성능 지표
- **평균 처리 시간**: 약 1초/공고
- **메모리 사용량**: 안정적
- **네트워크 요청**: 페이지당 16개 (목록 1 + 상세 15)

## 재사용 가능한 패턴

### 1. Enhanced Base Scraper 활용
```python
class EnhancedKamcoScraper(StandardTableScraper):
    def __init__(self):
        super().__init__()
        # 사이트별 설정만 추가
```

### 2. JavaScript 함수 파싱 유틸리티
다른 정부기관 사이트에서도 활용 가능한 패턴:
- `goTo.view()` - 상세 페이지 이동
- `fn_egov_downFile()` - 파일 다운로드
- 정규표현식을 통한 파라미터 추출

### 3. 공지/일반 공고 통합 처리
상공회의소 등 다른 사이트에서도 적용 가능한 패턴

## 특별한 기술적 도전과 해결책

### 도전 1: JavaScript 네비게이션
**문제**: href="#" 링크로 실제 URL 파악 불가
**해결**: onclick 이벤트에서 함수 파라미터 추출하여 URL 재구성

### 도전 2: 세션 기반 파일 다운로드
**문제**: 단순 GET 요청 및 브라우저 자동화로도 파일 다운로드 불가
**해결**: 메타데이터 기반 접근법으로 전환
- JSON과 마크다운 형태로 파일 정보 완전 보존
- 실제 다운로드 제약 사항을 명확히 문서화
- 사용자가 수동으로 다운로드할 수 있는 완전한 URL 제공

### 도전 3: Enhanced Base Scraper 호환성
**문제**: 기존 BaseClass와 함수 시그니처 충돌
**해결**: 중복 함수 제거하고 BaseClass 인터페이스 준수

## 개발자를 위한 팁

1. **테스트 우선**: 목록 파싱 → 상세 페이지 → 파일 다운로드 순서로 단계별 검증
2. **JavaScript 분석**: 브라우저 개발자 도구로 onclick 이벤트 함수 확인 필수
3. **인코딩 주의**: UTF-8이지만 파일명 추출 시 다양한 인코딩 시도 필요
4. **BaseClass 활용**: 가능한 한 Enhanced Base Scraper의 기능 활용
5. **에러 처리**: 파일 다운로드 실패 시 에러 페이지 내용 확인으로 원인 파악

## 향후 개선 방안

1. **수동 인증 연동**: 사용자가 브라우저에서 KAMCO 로그인 후 세션 쿠키를 스크래퍼에 제공하는 방식
2. **API 연동**: KAMCO에서 공식 API를 제공할 경우 활용
3. **병렬 처리**: 상세 페이지 요청 병렬화로 성능 향상
4. **캐싱**: 중복 공고 방지를 위한 캐싱 메커니즘 강화
5. **메타데이터 활용도 향상**: 파일 타입별 분류, 크기별 통계 등 부가 기능

## 결론

KAMCO 스크래퍼는 JavaScript 기반 네비게이션과 세션 인증이 필요한 파일 다운로드라는 기술적 도전을 **메타데이터 기반 접근법**으로 해결했습니다. 

**주요 성과**:
1. **100% 본문 수집**: 45개 공고의 완전한 본문 추출
2. **완벽한 첨부파일 메타데이터**: 36개 공고에서 파일명, 크기, URL 완전 보존
3. **재사용 가능한 패턴**: JavaScript 함수 파싱 로직과 공지 처리 방식
4. **현실적인 한계 인정**: 다운로드 제약을 명확히 문서화하여 투명성 확보

이 접근법은 **완벽한 파일 다운로드보다는 정보의 완전성과 투명성**을 우선시하는 현실적인 해결책으로, 다른 세션 기반 인증이 필요한 정부기관 사이트에서도 활용 가능한 모델입니다.