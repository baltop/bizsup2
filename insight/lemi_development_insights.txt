# 축산환경관리원(LEMI) 스크래퍼 개발 인사이트

## 사이트 개요
- **사이트명**: 축산환경관리원 (Livestock Environmental Management Institute)
- **URL**: https://www.lemi.or.kr/board.do?boardno=24&menuno=71
- **사이트 코드**: lemi
- **개발일**: 2025-07-02

## 사이트 특성 분석

### 1. 기본 구조
- **게시판 타입**: 표준 HTML 테이블 기반 게시판
- **인코딩**: UTF-8
- **SSL**: 지원 (HTTPS)
- **페이지네이션**: GET 파라미터 방식 (?page_now=N)
- **공지사항**: 상단 고정형 (공지 라벨 포함)

### 2. HTML 구조 특징
```html
<!-- 목록 페이지 -->
<table class="list_tbl">
  <tbody>
    <tr class="tr_notice">  <!-- 공지사항 -->
      <td class="no"><b>공지</b></td>
      <td class="sbj"><a href="/view.do?...">제목</a></td>
      <td>작성자</td>
      <td>작성일</td>
    </tr>
    <tr>  <!-- 일반 공고 -->
      <td class="no">405</td>
      <td class="sbj"><a href="/view.do?...">제목</a></td>
      <td>작성자</td>
      <td><em>작성일</em>2025.06.16</td>
    </tr>
  </tbody>
</table>

<!-- 상세 페이지 -->
<h5 class="sbj">제목</h5>
<ul class="info">
  <li><em>작성일</em>2025.05.19</li>
  <li><em>조회</em>323,068</li>
</ul>
<div class="memoWrap">본문 내용</div>
<ul class="file">첨부파일 영역</ul>
```

### 3. 첨부파일 구조 분석
```html
<ul class="file">
  <li>
    <strong>첨부파일</strong>
    <a class="filename" href="javascript:download(3242)">파일명.hwp</a>
    <span class="byte">(용량 : 183KB / 다운로드수 : 135)</span>
    <a href="javascript:download(3242)"><img alt="다운로드" /></a>
  </li>
</ul>
```

**중요 발견사항**:
- JavaScript 다운로드 함수가 `href` 속성에 있음 (onclick이 아님)
- 파일 ID는 `download(숫자)` 형태로 추출
- 실제 다운로드 URL: `/common/imgload.do?fileno={파일ID}`
- 파일명 텍스트는 `class="filename"`이 있는 링크에서만 추출

## 기술적 구현 특징

### 1. Enhanced Base Scraper 상속
```python
from enhanced_base_scraper import StandardTableScraper

class EnhancedLemiScraper(StandardTableScraper):
    """축산환경관리원 전용 스크래퍼"""
```

### 2. 공지사항 포함 수집
- `tr_notice` 클래스 또는 "공지" 텍스트로 감지
- 공지사항도 일반 공고와 동일하게 처리
- 번호를 "공지"로 설정

### 3. 첨부파일 추출 로직
```python
def _extract_attachments(self, soup):
    # href 속성에서 JavaScript 함수 파싱
    if 'download(' in href:
        file_id_match = re.search(r'download\((\d+)\)', href)
        file_id = file_id_match.group(1)
        download_url = f"{self.base_url}/common/imgload.do?fileno={file_id}"
```

### 4. 한글 파일명 처리
- 서버에서 올바른 Content-Disposition 헤더 제공
- RFC 5987 형식 및 일반 filename 파라미터 모두 지원
- EUC-KR, UTF-8 다중 인코딩 시도

## 테스트 결과

### 1. 기본 수집 테스트 (3페이지)
- **수집 공고 수**: 42개 (공지 4개 + 일반 38개)
- **실행 시간**: 71.1초
- **HTTP 요청**: 45개
- **성공률**: 100%

### 2. 첨부파일 테스트
- **테스트 공고**: 3개
- **다운로드 파일**: 7개 (HWP, PDF, JPG)
- **파일 크기**: 49KB ~ 837KB (모두 다름, 오류 없음)
- **한글 파일명**: 완벽 처리

### 3. 파일 타입별 검증
```bash
# HWP 파일
file *.hwp
→ Hancom HWP (Hangul Word Processor) file, version 5.0

# PDF 파일  
file *.pdf
→ PDF document, version 1.4

# JPG 파일
file *.jpg
→ JPEG image data, JFIF standard 1.01
```

## 주요 해결책

### 1. 첨부파일 감지 문제
**문제**: 초기에 첨부파일이 감지되지 않음
**원인**: `onclick` 속성이 아닌 `href` 속성에 JavaScript 함수 포함
**해결**: href와 onclick 모두 확인하도록 수정

```python
# 수정 전
if 'download(' in onclick:

# 수정 후  
if 'download(' in href:
    download_pattern = href
elif 'download(' in onclick:
    download_pattern = onclick
```

### 2. 아이콘 링크 필터링
**문제**: 다운로드 아이콘 링크도 파싱됨
**해결**: `class="filename"`이 있는 링크만 처리

```python
if not filename or 'filename' not in link.get('class', []):
    continue
```

### 3. 날짜 형식 정리
**문제**: 작성일에 "작성일" 텍스트 포함
**해결**: 정규표현식으로 제거

```python
date = re.sub(r'^작성일', '', date).strip()
```

## 재사용 가능한 패턴

### 1. JavaScript 다운로드 함수 처리
```python
# 범용 JavaScript 함수 파싱
download_pattern = href if 'download(' in href else onclick
file_id_match = re.search(r'download\((\d+)\)', download_pattern)
```

### 2. 공지사항 감지
```python
# CSS 클래스와 텍스트 모두 확인
is_notice = ('tr_notice' in row.get('class', []) or '공지' in number)
```

### 3. 한글 파일명 안전 처리
```python
def sanitize_filename(self, filename: str) -> str:
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    return filename.strip('. ') if filename else "unnamed_file"
```

## 특별한 기술적 도전

### 1. 이미지 기반 본문 처리
일부 공고는 본문이 이미지로만 제공됨:
- `<img>` 태그의 `alt` 속성에서 텍스트 추출
- alt 텍스트가 충분히 길면 우선 사용
- 일반 텍스트 추출과 병행

### 2. 다양한 파일 형식 지원
- HWP (한글 워드프로세서)
- PDF (Adobe Portable Document Format)  
- JPG (JPEG 이미지)
- 각 형식별 올바른 MIME 타입 처리

### 3. 효율적인 중복 방지
Enhanced Base Scraper의 processed_titles 기능 활용:
- JSON 파일로 처리된 제목 관리
- 중복 처리 방지로 실행 시간 단축

## 성능 최적화

### 1. 요청 간격 조절
```python
self.delay_between_requests = 1.5  # 서버 부하 방지
```

### 2. 스트리밍 다운로드
```python
response = session.get(url, stream=True)
for chunk in response.iter_content(chunk_size=8192):
    f.write(chunk)
```

### 3. 타임아웃 설정
```python
self.timeout = 30  # 적절한 타임아웃
```

## 최종 평가

### 장점
- ✅ 안정적인 HTML 파싱
- ✅ 완벽한 한글 파일명 처리
- ✅ 다양한 파일 형식 지원
- ✅ 공지사항 포함 수집
- ✅ 효율적인 중복 방지

### 개선 가능 영역
- 이미지 기반 본문의 OCR 처리 (필요시)
- 더 많은 파일 형식 지원 확장
- 병렬 다운로드 (서버 정책 확인 필요)

### 재사용성
이 스크래퍼는 다음과 같은 사이트에 재사용 가능:
- 표준 HTML 테이블 기반 게시판
- JavaScript 다운로드 함수 사용
- 한글 파일명 지원 필요
- 공지사항이 있는 게시판

## 결론

축산환경관리원 스크래퍼는 Enhanced Base Scraper 아키텍처의 장점을 잘 활용한 성공적인 구현 사례입니다. 특히 첨부파일 처리와 한글 파일명 지원에서 뛰어난 성능을 보여주며, 향후 유사한 정부기관 사이트 스크래핑에 좋은 참고 모델이 될 것입니다.