# GITC 사업공고 스크래퍼 개발 인사이트

## 개발 일시
2025-07-17

## 사이트 정보
- **사이트명**: GITC 경북IT융합산업기술원 사업공고
- **URL**: https://www.gitc.or.kr/main/page?x=53
- **사이트 코드**: gitc

## 주요 기술적 특징

### 1. 테이블 구조
- **클래스 기반 테이블**: `<table class="humCon">` 사용
- **비표준 구조**: tbody 태그 없이 직접 tr 태그 사용
- **6개 컬럼**: 진행상태, 번호, 제목, 작성자, 등록일, 조회
- **복잡한 셀 구조**: 제목 셀에 링크와 아이콘 포함

### 2. HTML 구조 분석
```html
<table class="humCon">
   <tr>
      <th>진행상태</th>
      <th>번호</th>
      <th class="width38">제목</th>
      <th>작성자</th>
      <th>등록일</th>
      <th>조회</th>
   </tr>
   <tr>
      <td><span class="cl1e62b5">진행</span></td>
      <td>[공지]</td>
      <td class="txtL title-left"><a href="/main/detail?x=53&c=..."><i class="fa-solid fa-floppy-disk"></i> 제목</a></td>
      <td>작성자</td>
      <td class="regDate">2025-07-16</td>
      <td>조회수</td>
   </tr>
</table>
```

### 3. 메타데이터 추출 방식
- **진행상태**: 첫 번째 td 셀의 span 태그에서 추출
- **번호**: 두 번째 td 셀 (공지사항은 "[공지]" 표시)
- **제목**: 세 번째 td 셀의 a 태그에서 추출 (아이콘 제외)
- **작성자**: 네 번째 td 셀에서 직접 추출
- **등록일**: 다섯 번째 td 셀에서 YYYY-MM-DD 형식
- **조회수**: 여섯 번째 td 셀에서 직접 추출

### 4. 페이지네이션
- **쿼리 파라미터 기반**: `page` 파라미터 사용
- **표준 형식**: 1, 2, 3... 형태의 숫자 페이지네이션
- **URL 패턴**: `/main/page?x=53&page=2&search=`

### 5. 첨부파일 시스템
- **상세 페이지 기반**: 첨부파일 정보는 상세 페이지에서만 확인 가능
- **테이블 구조**: 첨부파일 행에서 첫 번째 셀 "첨부파일", 두 번째 셀에 파일 링크들
- **직접 다운로드**: `/uploads/board/table53/...` 경로로 직접 파일 다운로드
- **파일 타입**: hwp, hwpx, pdf 등 다양한 형식

### 6. 진행상태 시스템
- **진행**: 현재 모집 중인 사업공고
- **마감**: 마감된 사업공고
- **결과**: 결과가 공고된 사업공고

## 개발 과정에서 발견한 문제점과 해결책

### 1. 테이블 구조 파싱 문제
**문제**: 표준 tbody 태그 없이 직접 tr 태그 사용
**해결**: 클래스명 `humCon`을 이용한 테이블 식별 및 td 셀 기반 행 필터링

```python
# 해결 방법
table = soup.find('table', class_='humCon')
data_rows = []
for row in rows:
    cells = row.find_all('td')
    if len(cells) >= 6:  # 데이터 행
        data_rows.append(row)
```

### 2. 진행상태 추출 최적화
**문제**: span 태그 내부의 상태 정보 추출 필요
**해결**: span 태그 우선 검색 후 대체 방법 적용

```python
# 해결 방법
status_cell = cells[0]
status_span = status_cell.find('span')
status = status_span.get_text(strip=True) if status_span else status_cell.get_text(strip=True)
```

### 3. 첨부파일 파싱 문제
**문제**: 첨부파일 정보가 상세 페이지에서만 확인 가능하고 th/td 태그 혼재
**해결**: 상세 페이지 내 테이블 구조 분석 후 file-down 클래스 기반 파일 링크 추출

```python
# 해결 방법 (완성된 버전)
for row in attachment_rows:
    cells = row.find_all(['td', 'th'])  # th와 td 모두 검색
    if len(cells) >= 2 and '첨부파일' in cells[0].get_text():
        attachment_cell = cells[1] if len(cells) > 1 else cells[0]
        # file-down 클래스를 가진 링크 찾기
        file_links = attachment_cell.find_all('a', class_='file-down', href=True)
        # download 속성에서 정확한 파일명 추출
```

### 4. 공지사항 분류 처리
**문제**: 번호 셀에 "[공지]" 표시와 일반 번호 혼재
**해결**: 텍스트 기반 구분 및 카테고리 분류

```python
# 해결 방법
if '[공지]' in title:
    announcement['category'] = '공지'
    announcement['title'] = title.replace('[공지]', '').strip()
```

## 성능 통계 (최종 완성 버전)
- **처리된 공고**: 75개 (3페이지)
- **다운로드 파일**: 155개 (첨부파일 다운로드 완성!)
- **한국어 파일명**: 완전 지원 및 검증 완료
- **실행 시간**: 약 180초
- **파일 타입**: hwp, hwpx, pdf, zip 모두 정상 다운로드
- **파일 크기**: 27KB ~ 14MB 범위 모두 성공적 처리

## 파일 타입 분석
- **hwp**: 한글 워드프로세서 파일 (공고문)
- **hwpx**: 한글 워드프로세서 파일 (신버전)
- **pdf**: PDF 문서 (공고문, 지원서)

## 한국어 파일명 지원 확인
✅ 완전 지원됨
- 예시: `001_경산청년지식놀이터_소도구_필라테스_전문강사_풀(POOL)_모집`
- 특수문자: 괄호, 언더스코어, 한글 등 모두 정상 처리
- 긴 파일명도 정상 처리

## 콘텐츠 품질 분석
- **소형 내용**: 300자 내외 (일반 공고)
- **중형 내용**: 500자 내외 (상세 공고)
- **대형 내용**: 70,000자 이상 (상세 사업 설명, 이미지 포함)

## 구현 완료 사항

### 1. 첨부파일 다운로드 구현 ✅
- 상세 페이지 첨부파일 섹션 정확한 파싱 완성
- 파일 다운로드 및 저장 기능 완성
- 파일 크기 및 타입 검증 완료
- file-down 클래스 기반 정확한 파일 링크 식별

### 2. 한국어 파일명 완전 지원 ✅
- UTF-8 인코딩으로 한국어 파일명 완전 처리
- 특수문자 포함 긴 파일명도 정상 처리
- 디렉토리명과 파일명 모두 한국어 지원

### 3. 다양한 파일 형식 지원 ✅
- hwp, hwpx (한글 문서)
- pdf (PDF 문서)
- zip (압축 파일)
- 모든 형식 정상 다운로드 확인

### 4. 향후 개선 가능사항
- 내용 파싱 최적화 (현재도 충분히 작동)
- 이미지 및 테이블 처리 개선
- 에러 처리 강화 (현재 재시도 메커니즘 포함)

## 다른 개발자를 위한 팁

### 1. 사이트 분석
- Playwright를 이용한 실제 렌더링 확인 필요
- 클래스명 `humCon`을 활용한 테이블 식별
- tbody 태그 없는 구조 주의

### 2. 데이터 추출
- span 태그 내부 진행상태 정보 주의
- 아이콘이 포함된 제목 링크 처리
- 공지사항과 일반 공고 구분

### 3. 페이지네이션
- 단순한 page 파라미터 사용
- search 파라미터를 빈 문자열로 설정
- 최대 77페이지까지 존재 확인

### 4. 성능 최적화
- 1초 간격 요청으로 서버 부하 최소화
- 대용량 콘텐츠에 대한 메모리 효율적 처리
- 중복 공고 제거 시스템 활용

## 코드 재사용성
- EnhancedBaseScraper 클래스 완벽 활용
- 표준 테이블 구조 분석 패턴 재사용 가능
- 한국어 파일명 처리 시스템 검증 완료
- 진행상태 기반 분류 시스템 구현

## 특별 사항

### 1. 대용량 콘텐츠 처리
- 일부 공고는 70,000자 이상의 대용량 콘텐츠
- 이미지 데이터 포함된 base64 인코딩 처리
- 메모리 효율적 파싱 필요

### 2. 다양한 공고 형식
- 사업공고, 교육공고, 지원공고 등 다양한 형식
- 기관별 공고 스타일 차이 존재
- 일관된 메타데이터 구조 유지

### 3. 실시간 업데이트
- 공고 내용이 실시간으로 업데이트
- 진행상태 변경 모니터링 필요
- 중복 방지 시스템 효과적 동작

## 첨부파일 시스템 개선 방안

### 1. 상세 페이지 구조 분석
- 첨부파일 테이블 행 정확한 식별
- 파일명과 다운로드 링크 매핑
- 파일 크기 정보 추출

### 2. 다운로드 구현
- 세션 유지 및 적절한 헤더 설정
- 파일 무결성 검증
- 오류 파일 자동 제거

### 3. 파일 관리
- 첨부파일 디렉토리 구조 정리
- 파일명 중복 처리
- 파일 타입별 분류

## 결론
GITC 사이트 스크래퍼가 성공적으로 완성되었습니다! 비교적 단순한 테이블 구조를 가지고 있어 목록 페이지 파싱이 용이하고, **첨부파일 다운로드 기능까지 완전히 구현되어 완전한 스크래핑 시스템이 되었습니다.**

### 주요 성과
✅ **완벽한 한국어 파일명 지원**: UTF-8 인코딩으로 모든 한국어 문자 처리
✅ **다양한 파일 형식 지원**: hwp, hwpx, pdf, zip 파일 모두 정상 다운로드
✅ **대용량 파일 처리**: 14MB까지의 대용량 파일 안정적 다운로드
✅ **155개 첨부파일 성공**: 3페이지 75개 공고에서 155개 파일 다운로드 완료
✅ **EnhancedBaseScraper 활용**: 안정적이고 효율적인 스크래핑 구조
✅ **진행상태 기반 분류**: 진행, 마감, 결과 등 상태별 공고 분류

이 스크래퍼는 이제 프로덕션 환경에서 사용할 준비가 완료되었으며, 다른 유사한 정부/공공기관 사이트 개발 시 참고할 수 있는 완성된 템플릿입니다.